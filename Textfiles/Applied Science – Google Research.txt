Applied Science ? Google Research Google Research Google Research Philosophy Research Areas Publications People Tools & Downloads Outreach Careers Blog Teams ? Applied Science Combining computer science with physics and biology to create breakthroughs that help the world. About the team Computer science and natural science are complementary: breakthroughs in one can lead to remarkable advances in the other. The goal of the Applied Science organization at Google is to cross-fertilize these two fields. There are four main efforts in Applied Science: Quantum Computing, Google Accelerated Science, Climate and Energy, and Scientific Computing Tools. Quantum Computing uses advances in applied physics to push the state-of-the-art in computation. Google Accelerated Science and Climate and Energy do the opposite: they use the latest advances in machine learning and artificial intelligence to accelerate progress in natural sciences, including societally-important areas such as biomedical research and zero-carbon energy sources. Finally, we supply Scientific Computing Tools such as Colab to many internal groups to enhance their data and machine learning productivity. Research areas Algorithms and Theory General Science Health & Bioscience Machine Intelligence Machine Perception Quantum Computing Team focus summaries Climate and Energy The Climate & Energy team is exploring how to use large-scale computing and machine intelligence to diminish or avoid climate disruption. We partner with fusion companies to accelerate the progress of commercially viable fusion, model techno-economic scenarios for decarbonization, research new techniques for carbon sequestration, and look for novel ways to improve our understanding of earth's ecosystem response to climate change. Physics The physics team seeks to combine advances in machine learning and other Google technologies to advance our understanding of the physical world. Current projects range from machine learning for scientific computing, developing efficient algorithms for solving nonlinear partial differential equations, applying differentiable algorithms to interpret microscopy data, enabling microscopy on phones, and building algorithms for understanding dysarthric speech. Quantum AI The Quantum AI Lab is building quantum processors and algorithms to dramatically accelerate computational tasks for machine intelligence. We are developing quantum algorithms with a particular focus on those which can already run on today?s pre-error corrected quantum processors. Quantum algorithms for optimization, sampling, and quantum simulation hold the promise of dramatic speedups over the fastest classical computers. Learn more Highlighted projects Scaling Up Fundamental Quantum Chemistry Simulations on Quantum Hardware Scaling Up Fundamental Quantum Chemistry Simulations on Quantum Hardware Accurate computational prediction of chemical processes from the quantum mechanical laws that govern them is a tool that can unlock new frontiers in chemistry, improving a wide variety of industries. Announcing OpenFermion: The Open Source Chemistry Package for Quantum Computers Announcing OpenFermion: The Open Source Chemistry Package for Quantum Computers OpenFermion is a library for simulating the systems of interacting electrons (fermions) which give rise to the properties of matter. Towards an exact (quantum) description of chemistry Towards an exact (quantum) description of chemistry The goal of our experiment was to use quantum hardware to efficiently solve the molecular electronic structure problem, which seeks the solution for the lowest energy configuration of electrons in the presence of a given nuclear configuration. Featured publications Machine learning accelerated computational fluid dynamics Preview Abstract Numerical simulation of fluids plays an essential role in modeling many physical phenomena, such as in weather, climate, aerodynamics and plasma physics. Fluids are well described by the Navier-Stokes equations, but solving these equations at scale remains daunting, limited by the computational cost of resolving the smallest spatiotemporal features. This leads to unfavorable trade-offs between... View details Machine learning accelerated computational fluid dynamics Ayya Alieva, Dmitrii Kochkov, Jamie Alexander Smith, Michael Brenner, Qing Wang, Stephan Hoyer Proceedings of the National Academy of Sciences USA (2021) Kohn-Sham equations as regularizer: building prior knowledge into machine-learned physics Preview Abstract Including prior knowledge is important for effective machine learning models in physics and is usually achieved by explicitly adding loss terms or constraints on model architectures. Prior knowledge embedded in the physics computation itself rarely draws attention. We show that solving the Kohn-Sham equations when training neural networks for the exchange-correlation functional provides an... View details Kohn-Sham equations as regularizer: building prior knowledge into machine-learned physics Li Li, Stephan Hoyer, Ryan Pederson, Ruoxi Sun, Ekin Dogus Cubuk, Patrick Francis Riley, Kieron Burke Phys. Rev. Lett., vol. 126 (2021), pp. 036401 Exponential suppression of bit or phase flip errors with repetitive quantum error correction Preview Abstract Realizing the potential of quantum computing will require achieving sufficiently low logical error rates. Many applications call for error rates below 10^-15, but state-of-the-art quantum platforms typically have physical error rates near 10^-3. Quantum error correction (QEC) promises to bridge this divide by distributing quantum logical information across many physical qubits so that errors... View details Exponential suppression of bit or phase flip errors with repetitive quantum error correction Adam Jozef Zalcman, Alan Derk, Alan Ho, Alex Opremcak, Alexander Korotkov, Alexandre Bourassa, Andre Gregory Petukhov, Andreas Bengtsson, Andrew Dunsworth, Anthony Megrant, Austin Fowler, B?lint Pat?, Benjamin Chiaro, Benjamin Villalonga, Brian Burkett, Brooks Riley Foxen, Catherine Erickson, Charles Neill, Chris Quintana, Cody Jones, Craig Michael Gidney, Daniel Eppens, Daniel Sank, Dave Landhuis, David A Buell, Doug Strain, Dvir Kafri, Edward Farhi, Eric Ostby, Erik Lucero, Evan Jeffrey, Fedor Kostritsa, Frank Carlton Arute, Hartmut Neven, Igor Aleiner, Jamie Yao, Jarrod Ryan McClean, Jeremy Patterson Hilton, Jimmy Chen, Jonathan Arthur Gross, Joseph Bardin, Josh Mutus, Juan Atalaya, Julian Kelly, Kevin Miao, Kevin Satzinger, Kostyantyn Kechedzhi, Kunal Arya, Marco Szalay, Marissa Giustina, Masoud Mohseni, Matt McEwen, Matt Trevithick, Matthew Neeley, Matthew P Harrigan, Michael Broughton, Michael Newman, Murphy Yuezhen Niu, Nicholas Bushnell, Nicholas Redd, Nicholas Rubin, Ofer Naaman, Orion Martin, Paul Victor Klimov, Pavel Laptev, Pedram Roushan, Ping Yeh, Rami Barends, Roberto Collins, Ryan Babbush, Sabrina Hong, Sean Demura, Sean Harrington, Seon Kim, Sergei Isakov, Sergio Boixo, Ted White, Thomas E O'Brien, Trent Huang, Trevor Mccourt, Vadim Smelyanskiy, Vladimir Shvarts, William Courtney, Wojtek Mruczkiewicz, Xiao Mi, Yu Chen, Zhang Jiang Nature (2021) GAN-Mediated Batch Equalization Preview Abstract Advances in automation and imaging have made it possible to capture large imagedatasets for experiments that span multiple weeks (i.e. batches). However, almostall images experience batch-to-batch variation due to uncontrollable noise (e.g.different stain intensity or illumination conditions), and such complication makesit difficult to make biological comparison across all of the conditions... View details GAN-Mediated Batch Equalization Arun Narayanaswamy, Cassandra Xia, Mike Ando, Subhashini Venugopalan, Wesley Qian bioRxiv (2020) Accurately computing electronic properties of materials using eigenenergies Preview Abstract A promising approach to study quantum materials is to simulate them on an engineered quantum platform. However, achieving the accuracy needed to outperform classical methods has been an outstanding challenge. Here, using superconducting qubits, we provide an experimental blueprint for a programmable and accurate quantum matter simulator and demonstrate how to probe fundamental electronic... View details Accurately computing electronic properties of materials using eigenenergies Adam Jozef Zalcman, Alan Derk, Alan Ho, Alex Opremcak, Alexander Korotkov, Andre Gregory Petukhov, Andreas Bengtsson, Andrew Dunsworth, Anthony Megrant, Austin Fowler, B?lint Pat?, Benjamin Chiaro, Benjamin Villalonga, Bob Benjamin Buckley, Brian Burkett, Brooks Riley Foxen, Catherine Erickson, Charles Neill, Chris Quintana, Cody Jones, Craig Michael Gidney, Daniel Eppens, Daniel Sank, Dave Landhuis, David A Buell, Doug Strain, Dvir Kafri, Edward Farhi, Eric Ostby, Erik Lucero, Evan Jeffrey, Fedor Kostritsa, Frank Carlton Arute, Hartmut Neven, Igor Aleiner, Jamie Yao, Jarrod Ryan McClean, Jeremy Patterson Hilton, Jimmy Chen, Jonathan Arthur Gross, Joseph Bardin, Josh Mutus, Juan Atalaya, Juan Campero, Julian Kelly, Kevin Miao, Kevin Satzinger, Kostyantyn Kechedzhi, Kunal Arya, Lev Ioffe, Marco Szalay, Marissa Giustina, Masoud Mohseni, Matt Jacob-Mitos, Matt McEwen, Matt Trevithick, Matthew Neeley, Matthew P Harrigan, Michael Blythe Broughton, Michael Newman, Murphy Yuezhen Niu, Nicholas Bushnell, Nicholas Redd, Nicholas Rubin, Ofer Naaman, Orion Martin, Paul Victor Klimov, Pavel Laptev, Pedram Roushan, Ping Yeh, Rami Barends, Roberto Collins, Ryan Babbush, Sabrina Hong, Sean Demura, Sean Harrington, Seon Kim, Sergei Isakov, Sergio Boixo, Ted White, Thomas E O'Brien, Trent Huang, Trevor Mccourt, Vadim Smelyanskiy, Vladimir Shvarts, William Courtney, William J. Huggins, Wojtek Mruczkiewicz, Xiao Mi, Yu Chen, Zhang Jiang arXiv preprint arXiv:2012.00921 (2020) Evaluating Attribution for Graph Neural Networks Preview Abstract Interpretability of machine learning models is critical to scientific understanding, AI safety, and debugging. Attribution is one approach to interpretability, which highlights input dimensions that are influential to a neural network?s prediction. Evaluation of these methods is largely qualitative for image and text models, because acquiring ground truth attributions requires expensive and... View details Evaluating Attribution for Graph Neural Networks Alexander B Wiltschko, Benjamin Sanchez-Lengeling, Brian Lee, Emily Reif, Jennifer Wei, Kevin James McCloskey, Lucy Colwell, Wesley Qian, Yiliu Wang Advances in Neural Information Processing Systems 33 (2020) Machine learning guided aptamer discovery Preview Abstract Aptamers are discovered by searching a large library for sequences with desirable binding properties. These libraries, however, are physically constrained to a fraction of the theoretical sequence space and limited to sampling strategies that are easy to scale. Integrating machine learning could enable identification of high-performing aptamers across this unexplored fitness landscape. We... View details Machine learning guided aptamer discovery Ali Bashir, Annalisa Pawlosky, Cory McLean, Geoff Davis, George Edward Dahl, Marc Berndl, Michelle Therese Dimon, Qin Yang, Scott Ferguson, Stephan Hoyer, Zan Armstrong Nature Communications (2021) Tuning Quantum Information Scrambling on a 53-Qubit Processor Preview Abstract As entanglement in a quantum system grows, initially localized quantum information is spread into the exponentially many degrees of freedom of the entire system. This process, known as quantum scrambling, is computationally intensive to study classically and lies at the heart of several modern physics conundrums. Here, we characterize scrambling of different quantum circuits on a 53-qubit... View details Tuning Quantum Information Scrambling on a 53-Qubit Processor Adam Jozef Zalcman, Alan Derk, Alan Ho, Alex Opremcak, Alexander Korotkov, Alexandre Bourassa, Andre Gregory Petukhov, Andreas Bengtsson, Andrew Dunsworth, Anthony Megrant, Austin Fowler, B?lint Pat?, Benjamin Chiaro, Benjamin Villalonga, Brian Burkett, Brooks Riley Foxen, Catherine Erickson, Charles Neill, Chris Quintana, Cody Jones, Craig Michael Gidney, Daniel Eppens, Daniel Sank, Dave Landhuis, David A Buell, Doug Strain, Dvir Kafri, Edward Farhi, Eric Ostby, Erik Lucero, Evan Jeffrey, Fedor Kostritsa, Frank Carlton Arute, Hartmut Neven, Igor Aleiner, Jamie Yao, Jarrod Ryan McClean, Jeffrey Marshall, Jeremy Patterson Hilton, Jimmy Chen, Jonathan Arthur Gross, Joseph Bardin, Josh Mutus, Juan Atalaya, Julian Kelly, Kevin Miao, Kevin Satzinger, Kostyantyn Kechedzhi, Kunal Arya, Marco Szalay, Marissa Giustina, Masoud Mohseni, Matt McEwen, Matt Trevithick, Matthew Neeley, Matthew P Harrigan, Michael Blythe Broughton, Michael Newman, Murphy Yuezhen Niu, Nicholas Bushnell, Nicholas Redd, Nicholas Rubin, Ofer Naaman, Orion Martin, Paul Victor Klimov, Pavel Laptev, Pedram Roushan, Ping Yeh, Rami Barends, Roberto Collins, Ryan Babbush, Sabrina Hong, Salvatore Mandra, Sean Demura, Sean Harrington, Seon Kim, Sergei Isakov, Sergio Boixo, Ted White, Thomas E O'Brien, Trent Huang, Trevor Mccourt, Vadim Smelyanskiy, Vladimir Shvarts, William Courtney, Wojtek Mruczkiewicz, Xiao Mi, Yu Chen, Zhang Jiang arXiv (2021) Focus Beyond Quadratic Speedups for Error-Corrected Quantum Advantage Preview Abstract In this perspective we discuss conditions under which it would be possible for a modest fault-tolerant quantum computer to realize a runtime advantage by executing a quantum algorithm with only a small polynomial speedup over the best classical alternative. The challenge is that the computation must finish within a reasonable amount of time while being difficult enough that the small quantum... View details Focus Beyond Quadratic Speedups for Error-Corrected Quantum Advantage Ryan Babbush, Jarrod Ryan McClean, Michael Newman, Craig Michael Gidney, Sergio Boixo, Hartmut Neven PRX Quantum, vol. 2 (2021), pp. 010103 Crystal Structure Search with Random Structure Relaxations Using Graph Networks Preview Abstract Materials design enables technologies critical to humanity, including combating climate change with solar cells and batteries. Many properties of a material are determined by its atomic crystal structure. However, prediction of the atomic crystal structure for a given material's chemical formula is a long-standing grand challenge that remains a barrier in materials design. We investigate a... View details Crystal Structure Search with Random Structure Relaxations Using Graph Networks Ekin Dogus Cubuk, Evan J. Reed, Gowoon Cheon, Kevin James McCloskey, Lusann Yang, Michael Brenner (2020) Some of our locations Cambridge Cambridge San Francisco Bay Area San Francisco Bay Area Seattle-Kirkland Seattle-Kirkland India India Some of our people John C. Platt Marc Berndl Michael Frumkin Jason Miller Hartmut Neven Lucy Colwell Marissa Giustina Varun Gulshan Michelle Dimon Lusann Yang Join us We're looking for talented people to join our team See opportunities Privacy Terms About Google Google Products Feedback